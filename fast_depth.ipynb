{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# https://www.kaggle.com/datasets/soumikrakshit/nyu-depth-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseUpSampleConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_depth = nn.Conv2d(in_channels = in_channels, out_channels=in_channels, kernel_size=(5,5), padding=2, groups=in_channels)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=in_channels) \n",
    "        self.relu6 = nn.ReLU6(inplace=True)\n",
    "        self.conv_pointwise = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1, 1), padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x  = self.relu6(self.bn1(self.conv_depth(x)))\n",
    "        return self.relu(self.bn2(self.conv_pointwise(x)))\n",
    "        \n",
    "class FastDepth(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mobile_v2_encoder = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        self.dec1 = DepthwiseUpSampleConvolution(320, 96)\n",
    "        self.dec2 = DepthwiseUpSampleConvolution(96, 32)\n",
    "        self.dec3 = DepthwiseUpSampleConvolution(32, 24)\n",
    "        self.dec4 = DepthwiseUpSampleConvolution(24, 16)\n",
    "        self.dec5 = DepthwiseUpSampleConvolution(16, 32)\n",
    "        self.final_conv = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "        self.values = self.layers_position = {1, 3, 6}\n",
    "\n",
    "    def forward(self, x):\n",
    "        # layers = {}\n",
    "        x = self.mobile_v2_encoder.features[0](x)\n",
    "        x = self.mobile_v2_encoder.features[1](x)\n",
    "        layer1 = x\n",
    "        x = self.mobile_v2_encoder.features[2](x)\n",
    "        x = self.mobile_v2_encoder.features[3](x)\n",
    "        layer2 = x\n",
    "        x = self.mobile_v2_encoder.features[4](x)\n",
    "        x = self.mobile_v2_encoder.features[5](x)\n",
    "        x = self.mobile_v2_encoder.features[6](x)\n",
    "        layer3 = x\n",
    "        x = self.mobile_v2_encoder.features[7](x)\n",
    "        x = self.mobile_v2_encoder.features[8](x)\n",
    "        x = self.mobile_v2_encoder.features[9](x)\n",
    "        x = self.mobile_v2_encoder.features[10](x)\n",
    "        x = self.mobile_v2_encoder.features[11](x)\n",
    "        x = self.mobile_v2_encoder.features[12](x)\n",
    "        x = self.mobile_v2_encoder.features[13](x)\n",
    "        x = self.mobile_v2_encoder.features[14](x)\n",
    "        x = self.mobile_v2_encoder.features[15](x)\n",
    "        x = self.mobile_v2_encoder.features[16](x)\n",
    "        x = self.mobile_v2_encoder.features[17](x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.dec2(x)\n",
    "        x = x + layer3\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.dec3(x)\n",
    "        x = x + layer2\n",
    "\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.dec4(x)\n",
    "        x = x + layer1\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.dec5(x)\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2NormActivation(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu6 = nn.ReLU6(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu6(self.bn(self.conv(x)))\n",
    "    \n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, t, in_channels, out_channels, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            Conv2NormActivation(in_channels, t * in_channels, kernel_size=1, stride=1, padding=0, groups=1), # unchanged data entry\n",
    "            Conv2NormActivation(t * in_channels, t * in_channels, kernel_size=3, stride=s, padding=1, groups= t * in_channels),\n",
    "            nn.Conv2d(t * in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_DATA = \"./nyu_data/data/nyu2_train.csv\"\n",
    "TEST_DATA = \"./nyu_data/data/nyu2_test.csv\"\n",
    "MAX_TRAINING_VALUE = 255\n",
    "MAX_VALIDATION_VALUE = 10000 # 10 meters expressed in milimiters\n",
    "\n",
    "class DepthImageDataset(Dataset):\n",
    "    def __init__(self, csv_file_name, transform=None):\n",
    "        self.transform = transform\n",
    "        self.files_paths = []\n",
    "        self.label_paths = []\n",
    "        with open(csv_file_name, mode ='r') as file:\n",
    "            csvFile = csv.reader(file)\n",
    "            for lines in csvFile:\n",
    "                self.files_paths.append(\"./nyu_data/\" + lines[0])\n",
    "                self.label_paths.append(\"./nyu_data/\" + lines[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files_paths)\n",
    "    \n",
    "    def get_my_item(self, idx):\n",
    "        return self.__getitem__(idx)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.files_paths[idx], flags=cv2.IMREAD_COLOR)\n",
    "        depth_img = cv2.imread(self.label_paths[idx], flags=cv2.IMREAD_UNCHANGED)\n",
    "        if (depth_img.dtype == np.uint8):\n",
    "            depth_img = depth_img / MAX_TRAINING_VALUE\n",
    "        else:\n",
    "            depth_img = depth_img / MAX_VALIDATION_VALUE\n",
    "        if (self.transform == None):\n",
    "            return np.array(img, dtype=np.float32), depth_img\n",
    "        transformed = self.transform(image=np.array(img, dtype=np.float32), mask=depth_img)\n",
    "        return transformed['image'], transformed['mask'].unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH_MODEL = \"./trained_fast_depth.pth\"\n",
    "RELATIVE_ERROR = 0.15\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_cuda_model(load_data_path: bool):\n",
    "    model = FastDepth()\n",
    "    if load_data_path and os.path.isfile(PATH_MODEL):\n",
    "        print(\"A citit dintr-ul fisier\")\n",
    "        model.load_state_dict(torch.load(PATH_MODEL, weights_only=True))\n",
    "    else:\n",
    "        print('Nu s-a gasit modelul la data path-ul specificat')\n",
    "    model = model.to(DEVICE)\n",
    "    print(\"Device-ul folosite este\", DEVICE)\n",
    "    print(\"Modelul a fost creat cu succes\")\n",
    "    return model\n",
    "\n",
    "def get_cpu_model(load_data_path: bool):\n",
    "    model = FastDepth()\n",
    "    if load_data_path and os.path.isfile(PATH_MODEL):\n",
    "        model.load_state_dict(torch.load(PATH_MODEL, weights_only=True))\n",
    "    else:\n",
    "        print('Nu s-a gasit modelul la data path-ul specificat')\n",
    "    print(\"Device-ul folosite este cpu\")\n",
    "    return model\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, model : FastDepth, patience, path):\n",
    "        self.path = path\n",
    "        self.patience = patience\n",
    "        self.model = model\n",
    "        self.current_patience = patience\n",
    "        self.current_loss = float('inf')\n",
    "\n",
    "    def should_continue(self, loss):\n",
    "        if (loss < self.current_loss):\n",
    "            self.current_loss = loss\n",
    "            self.current_patience = self.patience\n",
    "            torch.save(self.model.state_dict(), PATH_MODEL)\n",
    "            return True\n",
    "        self.current_patience -= 1\n",
    "        if (self.current_patience == 0): return False\n",
    "        return True\n",
    "    \n",
    "def plot_losses(train_losses: list[float], validation_losses: list[float], label_x : str, label_y : str, title : str) -> None:\n",
    "    \"\"\"Plots training and validation losses over epochs.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_losses, label=label_x, marker=\"o\")\n",
    "    plt.plot(validation_losses, label=label_y, marker=\"o\")\n",
    "    plt.xlabel(label_x)\n",
    "    plt.ylabel(label_y)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_learning_rate(learning_rate_list):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(learning_rate_list, label=\"LearningRate\", marker=\"o\")\n",
    "    plt.title(\"Learning Rate curve\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def compute_depth_accuracy_batch_photos(found_depth: torch.Tensor, depth: torch.Tensor, epsilon=1e-6):\n",
    "    relative_error = torch.abs(found_depth - depth) / (depth + epsilon) \n",
    "    right_examples = relative_error < RELATIVE_ERROR\n",
    "    total_elements = right_examples.numel()  \n",
    "    return torch.sum(right_examples).float() / total_elements\n",
    "\n",
    "def train_depth(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0 \n",
    "    idx = 0\n",
    "    for (inputs, labels) in dataloader:\n",
    "        idx += 1\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += compute_depth_accuracy_batch_photos(outputs, labels).item()\n",
    "    return train_loss / idx, train_accuracy / idx \n",
    "\n",
    "def test_depth(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        validation_accuracy = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            output = model(inputs)\n",
    "            current_acc = compute_depth_accuracy_batch_photos(output, labels).item()\n",
    "            validation_loss += criterion(output, labels).item()\n",
    "            validation_accuracy += current_acc\n",
    "        return validation_loss / len(dataloader), validation_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_loss_function(found_depth: torch.Tensor, depth: torch.Tensor):\n",
    "    meanAbsoluteError = torch.mean(torch.abs(found_depth - depth))\n",
    "    grad_found_x = found_depth[:,:,:-1,:] - found_depth[:,:,1:,:]\n",
    "    grad_found_y = found_depth[:,:,:,:-1] - found_depth[:,:,:,1:]\n",
    "    grad_truth_x = depth[:,:,:-1,:] - depth[:,:,1:,:]\n",
    "    grad_truth_y = depth[:,:,:,:-1] - depth[:,:,:,1:]\n",
    "    gradientEdgeLoss = torch.mean(torch.abs((grad_found_x - grad_truth_x))) + \\\n",
    "        torch.mean(torch.abs((grad_found_y - grad_truth_y))) \n",
    "    mean_found, std_found = found_depth.mean(), found_depth.std()\n",
    "    mean_truth, std_truth = depth.mean(), depth.std()\n",
    "    numerator = (2 * mean_found * mean_truth + 1e-5) * (2 * std_found * std_truth + 1e-5)\n",
    "    denominator =  (mean_found * mean_found + mean_truth * mean_truth + 1e-5) * (std_found * std_found + std_truth * std_truth + 1e-5)\n",
    "    structuralSimilarityLoss = (1 - numerator / denominator) / 2\n",
    "    return 0.6 * meanAbsoluteError + 0.2 * gradientEdgeLoss + structuralSimilarityLoss\n",
    " \n",
    "def get_optimized_loss_hyperparameters(model : FastDepth, parameters):\n",
    "    early_stopper = EarlyStopping(model, parameters[\"early_stopper\"], PATH_MODEL)\n",
    "    criterion = compute_new_loss_function\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=parameters[\"lr_optimizer\"], weight_decay=parameters[\"weight_decay_factor\"])\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=parameters[\"lr_optimizer\"], momentum=parameters[\"momentum\"], weight_decay=parameters[\"weight_decay_factor\"])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=parameters['gamma_lr'], patience=parameters['patience'])\n",
    "    return early_stopper, criterion, optimizer, lr_scheduler\n",
    "\n",
    "def get_default_hyperparameters(model :FastDepth, parameters):\n",
    "    early_stopper = EarlyStopping(model, parameters[\"early_stopper\"], PATH_MODEL)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=parameters[\"lr_optimizer\"], momentum=parameters[\"momentum\"], weight_decay=parameters[\"weight_decay_factor\"])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=parameters['gamma_lr'], patience=parameters['patience'])\n",
    "    return early_stopper, criterion, optimizer, lr_scheduler\n",
    "\n",
    "def train_depth_model(data, parameters):\n",
    "    train_info = {\n",
    "        \"train_loss\": [],\n",
    "        \"validation_loss\" : [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"validation_accuracy\" : [],\n",
    "        \"lr\": []\n",
    "    }\n",
    "    \n",
    "    max_acc = 0\n",
    "    model = get_cuda_model(True)\n",
    "    early_stopper, criterion, optimizer, lr_scheduler = get_optimized_loss_hyperparameters(model, parameters) \n",
    "    for i in range(parameters[\"epochs\"]):\n",
    "        train_loss, train_acc = train_depth(model, data[\"train\"], optimizer, criterion)\n",
    "        val_loss, val_acc = test_depth(model, data[\"validation\"], criterion)\n",
    "        if (val_acc > max_acc):\n",
    "            max_acc = val_acc\n",
    "            print(\"acuratete maxima la epoca\", i)\n",
    "        lr_scheduler.step(val_loss)\n",
    "        print(val_loss, val_acc, \"epoch: \", i)\n",
    "        train_info[\"train_loss\"].append(train_loss)\n",
    "        train_info[\"validation_loss\"].append(val_loss)\n",
    "        train_info[\"train_accuracy\"].append(train_acc)\n",
    "        train_info[\"validation_accuracy\"].append(val_acc)\n",
    "        # train_info[\"lr\"].append(lr_scheduler.get_lr())\n",
    "        if not early_stopper.should_continue(val_loss): break\n",
    "    plot_losses(train_info[\"train_loss\"], train_info[\"validation_loss\"], \n",
    "            \"Train\", \"Validation\", \"Training and Validation Loss\")\n",
    "    plot_losses(train_info[\"train_accuracy\"], train_info[\"validation_accuracy\"], \n",
    "            \"Train\", \"Validation\", \"Training and Validation Accuracy\")\n",
    "    plot_learning_rate(train_info[\"lr\"])\n",
    "    model.to(\"cpu\")\n",
    "    return train_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 epoci pana acum\n",
    "parameters = {\n",
    "    \"batch_size\" : 8,\n",
    "    'epochs' : 50,\n",
    "    'lr_optimizer': 1e-2,\n",
    "    'gamma_lr': 0.3,\n",
    "    'weight_decay_factor': 1e-4,\n",
    "    'patience': 30,\n",
    "    'early_stopper': 5,\n",
    "    \"momentum\" : 0.9,\n",
    "}\n",
    "\n",
    "SIZE=(256, 320)\n",
    "\n",
    "\n",
    "train_transforms_no_normalization = A.Compose([\n",
    "    A.Resize(height=SIZE[0], width=SIZE[1]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_transforms = A.Compose([ \n",
    "    # A.VerticalFlip(p=0.5),\n",
    "    # A.HorizontalFlip(p=0.5),\n",
    "    A.Resize(height=SIZE[0], width=SIZE[1]),\n",
    "    A.Normalize(normalization='min_max'),\n",
    "    # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(height=SIZE[0], width=SIZE[1]),\n",
    "    A.Normalize(normalization='min_max'),\n",
    "    # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "datasets = {\n",
    "    \"train_no_transform\": DepthImageDataset(TRAIN_DATA, transform=train_transforms_no_normalization), \n",
    "    \"train\": DepthImageDataset(TRAIN_DATA, transform=train_transforms),\n",
    "    \"validation\": DepthImageDataset(TEST_DATA, transform=test_transforms)\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"train\": DataLoader(datasets['train'], batch_size=parameters[\"batch_size\"], shuffle=True, num_workers=4),\n",
    "    \"validation\": DataLoader(datasets['validation'], batch_size=parameters[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "}\n",
    "print(len(data['validation'].dataset))\n",
    "train_depth_model(data, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cpu_model(True)\n",
    "for iddx, (images, labels) in enumerate(data[\"validation\"]):\n",
    "    out = model(images)\n",
    "    print(compute_depth_accuracy_batch_photos(out, labels))\n",
    "    initial_image = images[0].permute((1, 2, 0))\n",
    "    labels_image = labels[0].permute((1, 2, 0))\n",
    "    output_image = out[0].permute((1, 2, 0))\n",
    "    labels_image = (labels_image.detach().cpu().numpy().squeeze())\n",
    "    output_image = (output_image.detach().cpu().numpy().squeeze())\n",
    "    plt.figure(figsize=(24, 24))\n",
    "    plt.subplot(1, 3, 1) \n",
    "    plt.imshow(initial_image)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(output_image)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(labels_image)\n",
    "    plt.axis('off')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_input = torch.rand(size=(1, 3, 480, 640))\n",
    "model_to_convert = FastDepth()\n",
    "model_to_convert.load_state_dict(torch.load(PATH_MODEL, weights_only=True))\n",
    "torch.onnx.export(model_to_convert, torch_input, \"fast_depth.onnx\", opset_version=11)\n",
    "import onnxruntime\n",
    "session = onnxruntime.InferenceSession(\"./fast_depth.onnx\")\n",
    "print(\"ONNX model loaded successfully in ONNX Runtime\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
